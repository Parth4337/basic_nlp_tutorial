{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "PROJ_DIR = os.path.join(os.environ['WORKSPACE'], 'tutorial/')\n",
    "\n",
    "if PROJ_DIR not in sys.path:\n",
    "    sys.path.append(PROJ_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The IMDB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data (most likely) already downloaded\r\n"
     ]
    }
   ],
   "source": [
    "!cd .. \\\n",
    "&& [ ! -f aclImdb_v1.tar.gz ] \\\n",
    "&& wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz \\\n",
    "&& tar -xzf  aclImdb_v1.tar.gz || echo \"Data (most likely) already downloaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "random.seed(2)\n",
    "\n",
    "MAXLEN = 64\n",
    "\n",
    "def read_files(datadir, sentiment, maxlen):\n",
    "    sent_dir = os.path.join(datadir, sentiment)\n",
    "    \n",
    "    tokens = [word_tokenize(open(os.path.join(sent_dir, sent_file)).read())[:maxlen]\n",
    "              for sent_file in os.listdir(sent_dir)[:1500]\n",
    "              if sent_file.endswith('.txt')]\n",
    "    labels = [sentiment] * len(tokens)\n",
    "    \n",
    "    return tokens, labels\n",
    "    \n",
    "    \n",
    "def shuffle(tokens, labels):\n",
    "    z = list(zip(tokens, labels))\n",
    "    random.shuffle(z)\n",
    "    return zip(*z)\n",
    "    \n",
    "    \n",
    "class IMDBDatset(Dataset):\n",
    "    def __init__(self, datadir, maxlen):\n",
    "        assert os.path.exists(datadir), datadir\n",
    "        \n",
    "        self.tokens = []\n",
    "        self.labels = []\n",
    "\n",
    "        pos_tokens, pos_labels = read_files(datadir, 'pos', maxlen)\n",
    "        neg_tokens, neg_labels = read_files(datadir, 'neg', maxlen)\n",
    "        \n",
    "        self.tokens.extend(pos_tokens + neg_tokens)\n",
    "        self.labels.extend(pos_labels + neg_labels)\n",
    "        \n",
    "        self.tokens, self.labels = shuffle(self.tokens, self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.tokens[item], self.labels[item]\n",
    "\n",
    "\n",
    "train_dataset = IMDBDatset(os.path.join(PROJ_DIR, 'aclImdb/train'), MAXLEN)\n",
    "test_dataset = IMDBDatset(os.path.join(PROJ_DIR, 'aclImdb/test'), MAXLEN)\n",
    "\n",
    "dev_dataset = copy.deepcopy(train_dataset)\n",
    "dev_dataset.tokens = dev_dataset.tokens[-1000:]\n",
    "dev_dataset.labels = dev_dataset.labels[-1000:]\n",
    "\n",
    "train_dataset.tokens = train_dataset.tokens[:2000]\n",
    "train_dataset.labels = train_dataset.labels[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1000, 3000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(dev_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1430 pos\n",
      "['My', 'favorite', 'movie', '.', 'What', 'a', 'great', 'story', 'this', 'really', 'was', '.', 'I', \"'d\", 'just', 'like', 'to', 'be', 'able', 'to', 'buy', 'a', 'copy', 'of', 'it', 'but', 'this', 'does', 'not', 'seem', 'possible', '.']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "    tokens, label = train_dataset[i]\n",
    "    if len(tokens) <= 32:\n",
    "        print(i, label)\n",
    "        print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'the', 'least', 'scary', 'film', 'i', 'have', 'ever', 'seen', '.', 'How', 'the', 'blob', 'manages', 'to', 'eat', 'anyone', 'is', 'the', 'biggest', 'mystery', 'of', 'the', 'film', '.', 'The', 'blob', 'moves', 'so', 'slowly', 'that', 'an', 'o.a.p', 'in', 'a', 'zimmerframe', 'could', 'escape', 'it', '.', 'The', 'blob', 'has', 'a', 'large', 'slice', 'of', 'luck', 'coming', 'across', 'a', 'typical', 'horror', 'film', 'woman', 'who', 'instead', 'of', 'running', 'away', 'stands', 'still', 'for'] \n",
      "\n",
      "['My', 'favorite', 'movie', '.', 'What', 'a', 'great', 'story', 'this', 'really', 'was', '.', 'I', \"'d\", 'just', 'like', 'to', 'be', 'able', 'to', 'buy', 'a', 'copy', 'of', 'it', 'but', 'this', 'does', 'not', 'seem', 'possible', '.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens, labels = train_dataset[1430-1:1430+1]\n",
    "for t in tokens:\n",
    "    print(t, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe vectors (most likely) already downloaded\r\n"
     ]
    }
   ],
   "source": [
    "!cd .. && [ ! -f glove.6B.zip ] \\\n",
    "&& wget http://nlp.stanford.edu/data/glove.6B.zip \\\n",
    "&& mkdir glove.6B \\\n",
    "&& tar -xzf glove.6B.zip -C glove.6B || echo \"GloVe vectors (most likely) already downloaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18757"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten(posts):\n",
    "    return [t for tokens in posts for t in tokens]\n",
    "\n",
    "vocab = set(flatten(train_dataset.tokens + dev_dataset.tokens))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "class WordEmbedder(nn.Module):\n",
    "    def __init__(self, vocab, glove_file):\n",
    "        super(WordEmbedder, self).__init__()\n",
    "        assert os.path.exists(glove_file) and glove_file.endswith('.txt'), glove_file\n",
    "        \n",
    "        self.emb_dim = None\n",
    "        \n",
    "        self.PAD_TOKEN = '<PAD>'\n",
    "        self.UNK_TOKEN = '<UNK>'\n",
    "        \n",
    "        index_to_word = [self.PAD_TOKEN, self.UNK_TOKEN]\n",
    "        index_to_vect = [None, None]\n",
    "        \n",
    "        with open(glove_file, 'r') as fp:\n",
    "            for line in fp:\n",
    "                line = line.split()\n",
    "                \n",
    "                if line[0] not in vocab:\n",
    "                    continue\n",
    "                \n",
    "                w = line[0]\n",
    "                v = np.array([float(value) for value in line[1:]])\n",
    "                \n",
    "                if self.emb_dim is None:\n",
    "                    self.emb_dim = v.shape[0]\n",
    "            \n",
    "                index_to_word.append(w)\n",
    "                index_to_vect.append(v)\n",
    "                \n",
    "        index_to_vect[0] = np.zeros(self.emb_dim)\n",
    "        index_to_vect[1] = np.mean(index_to_vect[2:], axis=0)\n",
    "    \n",
    "        self.embeddings = torch.from_numpy(np.array(index_to_vect)).float()\n",
    "        self.embeddings = nn.Embedding.from_pretrained(self.embeddings, freeze=False)\n",
    "        \n",
    "        self.index_to_word = {i: w for i, w in enumerate(index_to_word)}\n",
    "        self.word_to_index = {w: i for i, w in self.index_to_word.items()}\n",
    "    \n",
    "    def forward(self, samples):\n",
    "        pad_ix = self.word_to_index[self.PAD_TOKEN]\n",
    "        unk_ix = self.word_to_index[self.UNK_TOKEN]\n",
    "        \n",
    "        maxlen = max([len(s) for s in samples])\n",
    "        \n",
    "        encoded = [[self.word_to_index.get(token, unk_ix) for token in tokens] for tokens in samples]\n",
    "        masks = torch.zeros(len(samples), maxlen).long()\n",
    "        \n",
    "        # Padding and masking\n",
    "        for i in range(len(encoded)):\n",
    "            masks[i, :len(encoded[i])] = 1\n",
    "            encoded[i] += [pad_ix] * max(0, (maxlen - len(encoded[i])))\n",
    "        \n",
    "        encoded = torch.tensor(encoded).long()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            encoded = encoded.cuda()\n",
    "            masks = mask.cuda()\n",
    "        \n",
    "        result = {\n",
    "            'output': self.embeddings(encoded),\n",
    "            'mask': masks,\n",
    "            'encoded': encoded\n",
    "        }\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded:\n",
      "tensor([[   1,   15,    2,  317, 5226,  298,   42,   34,  587,  486,    4,    1,\n",
      "            2, 9139, 3938,    6, 2646, 1293,   15,    2,  771, 3523,    5,    2,\n",
      "          298,    4,    1, 9139, 1951,   98, 2789,   13,   30,    1,    8,    9,\n",
      "            1,   94, 2272,   21,    4,    1, 9139,   32,    9,  395, 5317,    5,\n",
      "         3616,  688,  477,    9, 2671, 3808,  298,  692,   39,  682,    5,  702,\n",
      "          389, 2017,  144,   11],\n",
      "        [   1, 2104,  873,    4,    1,    9,  331,  472,   38,  529,   16,    4,\n",
      "            1,  987,  117,  114,    6,   31,  593,    6,  857,    9, 3109,    5,\n",
      "           21,   35,   38,  246,   37, 1556,  498,    4,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0]])\n",
      "Mask:\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "embedder = WordEmbedder(vocab, os.path.join(PROJ_DIR, 'glove.6B/glove.6B.100d.txt'))\n",
    "\n",
    "tokens, labels = train_dataset[1430-1:1430+1]\n",
    "embedder_result = embedder(tokens)\n",
    "\n",
    "print(\"Encoded:\\n{}\".format(embedder_result['encoded']))\n",
    "print(\"Mask:\\n{}\".format(embedder_result['mask']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTMLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 hidden_dim,\n",
    "                 bidirectional=False,\n",
    "                 num_layers=1,\n",
    "                 drop_prob=0.3):\n",
    "        super(LSTMLayer, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(self.input_dim,\n",
    "                            self.hidden_dim // 2 if self.bidirectional else self.hidden_dim,\n",
    "                            num_layers=self.num_layers,\n",
    "                            bidirectional=self.bidirectional,\n",
    "                            dropout=drop_prob if self.num_layers > 1 else 0,\n",
    "                            batch_first=True)\n",
    "\n",
    "    def forward(self, vectors, mask):\n",
    "        batch_size = vectors.size(0)\n",
    "        max_length = vectors.size(1)\n",
    "        lengths = mask.sum(-1)\n",
    "\n",
    "        lstm_out, _ = self.lstm(vectors)  # (batch, seq_len, num_directions * hidden_size)\n",
    "\n",
    "        assert len(lstm_out.size()) == 3\n",
    "        assert lstm_out.size(0) == batch_size, \"The batch size should be the first dimension of the LSMT output\"\n",
    "        assert lstm_out.size(1) == max_length, \"The sequence length should be the second dimension\"\n",
    "        assert lstm_out.size(2) == self.hidden_dim\n",
    "\n",
    "        if self.bidirectional:\n",
    "            # Separate the directions of the LSTM\n",
    "            lstm_out = lstm_out.view(batch_size, max_length, 2, self.hidden_dim // 2)\n",
    "\n",
    "            # Pick up the last hidden state per direction\n",
    "            fw_last_hn = lstm_out[range(batch_size), lengths - 1, 0]  # (batch, hidden // 2)\n",
    "            bw_last_hn = lstm_out[range(batch_size), 0, 1]            # (batch, hidden // 2)\n",
    "\n",
    "            last_hn = torch.cat([fw_last_hn, bw_last_hn], dim=1)      # (batch, hidden // 2) -> (batch, hidden)\n",
    "        else:\n",
    "            last_hn = lstm_out[range(batch_size), lengths - 1]        # (batch, hidden)\n",
    "\n",
    "        result = {\n",
    "            'last_output': last_hn,\n",
    "            'outputs': lstm_out\n",
    "        }\n",
    "            \n",
    "        return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer = LSTMLayer(embedder.emb_dim, 64)\n",
    "lstm_result = lstm_layer(embedder_result['output'], embedder_result['mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3110, -0.1096, -0.0936, -0.0133,  0.0684,  0.1158,  0.0070, -0.0261,\n",
       "          0.3608, -0.0616, -0.0180, -0.1673,  0.0874,  0.0647, -0.1276,  0.2160,\n",
       "          0.1235,  0.0969,  0.0941,  0.0459,  0.0888,  0.1548,  0.2680,  0.0922,\n",
       "         -0.2873, -0.0229, -0.0592, -0.1303, -0.0644,  0.0026, -0.1048,  0.1234,\n",
       "         -0.0633,  0.2180,  0.0135,  0.0428, -0.1438, -0.0828,  0.1079,  0.1771,\n",
       "          0.3920, -0.3413, -0.0553,  0.2152, -0.2983, -0.3738, -0.1413,  0.0825,\n",
       "         -0.0946, -0.0011,  0.0431,  0.2841, -0.0211, -0.1301,  0.0652, -0.1148,\n",
       "          0.0383,  0.0912,  0.1139, -0.0533, -0.0022,  0.1915, -0.1320,  0.1496],\n",
       "        [ 0.2932, -0.0846, -0.1677,  0.0756, -0.0269,  0.1424, -0.0061,  0.0374,\n",
       "          0.3842, -0.0945, -0.0394, -0.1346,  0.0454, -0.0832, -0.1512,  0.2612,\n",
       "          0.0763, -0.0879,  0.0513,  0.0515, -0.1689,  0.1486,  0.1977,  0.1775,\n",
       "         -0.3069, -0.0157,  0.1164, -0.1034, -0.0488, -0.0016, -0.0595,  0.0881,\n",
       "          0.0191,  0.0950, -0.0577,  0.0828, -0.1240, -0.1379,  0.0077,  0.1792,\n",
       "          0.3585, -0.2764, -0.0013,  0.1298, -0.2217, -0.3663, -0.3002,  0.0631,\n",
       "         -0.1212, -0.0148, -0.0303,  0.2297,  0.0433, -0.1116, -0.0280, -0.1400,\n",
       "          0.1627,  0.0955,  0.1481, -0.0621, -0.0381,  0.1758,  0.0292,  0.1611]],\n",
       "       grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_result['last_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (research)",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
